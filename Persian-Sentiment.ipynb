{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ithabibi/Persian-Opinion-Mining-and-Sentiment-Analysis/blob/main/Persian-Sentiment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sMNPBU2OwSBw"
      },
      "source": [
        "# Persian Sentiment Analysis With Fasttext language Model and LSTM neural network\n",
        "### Persian sentiment analysis step by step guide\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "so there are 5 steps we going through with each other "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nS1VtmSF6wmn"
      },
      "source": [
        "## Step 1)Choose and Preparing word embedding model\n",
        "in this step we gonna to prepare [word embedding](https://towardsdatascience.com/introduction-to-word-embedding-and-word2vec-652d0c2060fa) model.\n",
        "there are too many ways to train a word embedding model for example :\n",
        "\n",
        "1.   Fasttext\n",
        "2.   ELMo (Embeddings from Language Models)\n",
        "3.   Universal Sentence Encoder \n",
        "4.   Word2Vec\n",
        "5.   GloVe (Global Vector)\n",
        "\n",
        "if you Want to know more then read [this article from Thomas Wolf](https://medium.com/huggingface/universal-word-sentence-embeddings-ce48ddc8fc3a) but now we gonna use Fasttext because it's Pretrained by Facebook and we can use it ( there is nothing to worry about this model it's pretty easy to train it by your self or your corpus facebook used Persian Wikipedia and some other staff as dataset for this model so it's just very simpler for us)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "both",
        "colab": {},
        "colab_type": "code",
        "id": "BELKe6-qixIA"
      },
      "outputs": [],
      "source": [
        "#@title Download, extract and load Fasttext word embedding model\n",
        "\n",
        "!wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.fa.300.bin.gz\n",
        "!gunzip /content/cc.fa.300.bin.gz\n",
        "\n",
        "!pip install pybind11==2.11.1\n",
        "!pip install fasttext==0.9.2 \n",
        "\n",
        "import fasttext \n",
        "\n",
        "%time\n",
        "model = fasttext.load_model(\"/content/cc.fa.300.bin\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### test tasttext model whit تتو word"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(model.get_dimension())\n",
        "print(model.get_word_vector('تتو').shape)\n",
        "print(model['تتو']) # get the vector of the word 'تتو'\n",
        "\n",
        "model.get_nearest_neighbors('تتو')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2ZKbBDbX7Mza"
      },
      "source": [
        "## Step 2) Normalize and Prepare dataset\n",
        "in this step we going to collect a dataset that crawled by [@minasmz](https://github.com/minasmz) it's not good and I only used 450 pos and 450 neg reviews from it.anyway here we will download the dataset and split it to train and test ( I created Train and Test then I filled it with data )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {},
        "colab_type": "code",
        "id": "nAQMVT05MMY4"
      },
      "outputs": [],
      "source": [
        "#@title Upload in google colab and prepare Dataset\n",
        "!wget https://raw.githubusercontent.com/ithabibi/Persian-Opinion-Mining-and-Sentiment-Analysis/main/sentiment_tagged_dataset.csv\n",
        "\n",
        "!pip install pandas==1.5.3\n",
        "!pip install numpy==1.23\n",
        "!pip install hazm==0.7.0\n",
        "\n",
        "import pandas\n",
        "import random\n",
        "import numpy\n",
        "import hazm\n",
        "\n",
        "# load and read sentiment_tagged dataset.csv file in tne path ./content/ in google colab. \n",
        "# this dataset include three element: Text,Score,Suggestion\n",
        "csv_dataset = pandas.read_csv(\"/content/sentiment_tagged_dataset.csv\")\n",
        "\n",
        "def CleanPersianText(text):\n",
        "  _normalizer = hazm.Normalizer()\n",
        "  text = _normalizer.normalize(text)\n",
        "  return text\n",
        "\n",
        "# Cleansing the dataset and creating a new list with two elements: \"text\" and \"suggestion\". (but without the third element: \"score\")\n",
        "# The new list is created by the zip command --> x= zip(csv_dataset['Text'],csv_dataset['Suggestion'])\n",
        "# valu of suggestion is 1,2,3 or pos,nat,neg\n",
        "revlist = list(map(lambda x: [CleanPersianText(x[0]),x[1]],zip(csv_dataset['Text'],csv_dataset['Suggestion'])))\n",
        "\n",
        "# Separation of positive and negative suggestions\n",
        "positive=list(filter(lambda x: x[1] == 1,revlist))\n",
        "neutral=list(filter(lambda x: x[1] == 2,revlist))\n",
        "negative=list(filter(lambda x: x[1] == 3,revlist))\n",
        "\n",
        "# print number of element exist in positive, neutral, negative, revlist list \n",
        "print(\"Posetive count {}\".format(len(positive)))\n",
        "print(\"Negetive count {}\".format(len(negative)))\n",
        "print(\"Natural  count {}\".format(len(neutral)))\n",
        "print(\"Total dataset count {}\".format(len(revlist)))\n",
        "\n",
        "# mix positive and negative suggestions for 450 element.\n",
        "# We chose 450 because the most negative comments were 450\n",
        "revlist_shuffle = positive[:450] + negative[:450]\n",
        "random.shuffle(revlist_shuffle)\n",
        "random.shuffle(revlist_shuffle)#double shuffle\n",
        "print(\"Total shuffle count {}\".format(len(revlist_shuffle)))\n",
        "\n",
        "# print random element from positive, neutral, negative List\n",
        "print(\"Posetive count : \",\"\\n\",positive[random.randrange(1,len(positive))])\n",
        "print(\"Negetive count : \",\"\\n\",negative[random.randrange(1,len(negative))])\n",
        "print(\"unknown  count : \",\"\\n\",neutral[random.randrange(1,len(neutral))])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {},
        "colab_type": "code",
        "id": "wUJceKehjfJ3"
      },
      "outputs": [],
      "source": [
        "#@title create and Prepare Train & Test data_structure with zero value\n",
        "vector_size = 300 #@param {type:\"integer\"}\n",
        "max_no_tokens = 20 #@param {type:\"integer\"}\n",
        "import numpy as np\n",
        "import keras.backend as K\n",
        "train_size = int(0.95*(len(revlist_shuffle)))\n",
        "test_size = int(0.05*(len(revlist_shuffle)))\n",
        "\n",
        "x_train = np.zeros((train_size, max_no_tokens, vector_size), dtype=K.floatx())\n",
        "y_train = np.zeros((train_size, 2), dtype=np.int32)\n",
        "\n",
        "x_test = np.zeros((test_size, max_no_tokens, vector_size), dtype=K.floatx())\n",
        "y_test = np.zeros((test_size, 2), dtype=np.int32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {},
        "colab_type": "code",
        "id": "jvcGBpjPwFL0"
      },
      "outputs": [],
      "source": [
        "#@title Fill X_Train, X_Test, Y_Train, Y_Test with digi-kala Dataset\n",
        "indexes = set(np.random.choice(len(revlist_shuffle), train_size + test_size, replace=False))\n",
        "\n",
        "for data_item, index in enumerate(indexes): # indexes include 500 items\n",
        "  Sentence = hazm.word_tokenize(revlist_shuffle[index][0])\n",
        "  for word in range(0,len(Sentence)):\n",
        "    if word >= max_no_tokens:\n",
        "      break\n",
        "    if Sentence[word] not in model.words: # model is fast text\n",
        "      continue\n",
        "    if data_item < train_size:\n",
        "      x_train[data_item, word, :] = model.get_word_vector(Sentence[word])\n",
        "    else:\n",
        "      x_test[data_item - train_size, word, :] = model.get_word_vector(Sentence[word])\n",
        "\n",
        "  if data_item < train_size:\n",
        "    y_train[data_item, :] = [1.0, 0.0] if revlist_shuffle[index][1] == 3 else [0.0, 1.0]\n",
        "  else:\n",
        "    y_test[data_item - train_size, :] = [1.0, 0.0] if revlist_shuffle[index][1] == 3 else [0.0, 1.0]\n",
        "    \n",
        "x_train.shape,x_test.shape,y_train.shape,y_test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dDunM15J7n8E"
      },
      "source": [
        "## Step 3) Config & Compile & Fir the LSTM model\n",
        "Now we will create our LSTM model then feed it our Train data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {},
        "colab_type": "code",
        "id": "_Mbfwpab3Yb8"
      },
      "outputs": [],
      "source": [
        "#@title Set batchSize and epochs\n",
        "batch_size = 500 #@param {type:\"integer\"}\n",
        "no_epochs = 200 #@param {type:\"integer\"}\n",
        "fasttext_model = model\n",
        "del model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {},
        "colab_type": "code",
        "id": "J1z_mq913jTq"
      },
      "outputs": [],
      "source": [
        "#@title Building Layer of LSTM Model\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv1D, Dropout, Dense, Flatten, LSTM, MaxPooling1D, Bidirectional\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import EarlyStopping, TensorBoard\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv1D(32, kernel_size=3, activation='elu', padding='same',\n",
        "                 input_shape=(max_no_tokens, vector_size)))\n",
        "model.add(Conv1D(32, kernel_size=3, activation='elu', padding='same'))\n",
        "model.add(Conv1D(32, kernel_size=3, activation='relu', padding='same'))\n",
        "model.add(MaxPooling1D(pool_size=3))\n",
        "\n",
        "model.add(Bidirectional(LSTM(512, dropout=0.2, recurrent_dropout=0.3)))\n",
        "\n",
        "model.add(Dense(512, activation='sigmoid'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(512, activation='sigmoid'))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(512, activation='sigmoid'))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.0001, decay=1e-6), metrics=['accuracy'])\n",
        "\n",
        "# tensorboard = TensorBoard(log_dir='logs/', histogram_freq=0, write_graph=True, write_images=True)\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.fit(x_train, y_train, batch_size=batch_size, shuffle=True, epochs=no_epochs,\n",
        "         validation_data=(x_test, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Step 4) Evaluate and Save our model\n",
        "in this step we evaluate LSTM model loss and accuracy metric\n",
        "loss: 0.5849 - accuracy: 0.8333"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "3TKsHaoO7HpW"
      },
      "outputs": [],
      "source": [
        "model.metrics_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "UpocYJkB7KMs"
      },
      "outputs": [],
      "source": [
        "model.evaluate(x=x_test, y=y_test, batch_size=32, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "U5xPkhZX7Qmq"
      },
      "outputs": [],
      "source": [
        "model.save('learned-persian-sentiment-fasttext.model')#Save the model for future use"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lJxZj2vr7uMO"
      },
      "source": [
        "# Step 5) test our model\n",
        "there is two form but it's just for showcase there is no diff between them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {},
        "colab_type": "code",
        "id": "xXt5rQ0qmyax"
      },
      "outputs": [],
      "source": [
        "user_text = \"\\u062E\\u06CC\\u0644\\u06CC \\u06AF\\u0648\\u0634\\u06CC\\u0647 \\u062E\\u0648\\u0628\\u06CC\\u0647. \\u062A\\u0634\\u062E\\u06CC\\u0635 \\u0686\\u0647\\u0631\\u0647 \\u062F\\u0627\\u0631\\u0647. \\u062F\\u0627\\u062E\\u0644 \\u062C\\u0639\\u0628\\u0647 \\u06A9\\u0627\\u0648\\u0631 \\u06AF\\u0648\\u0634\\u06CC \\u0648 \\u0645\\u062D\\u0627\\u0641\\u0638 \\u0635\\u0641\\u062D\\u0647 \\u062F\\u0627\\u0631\\u0647. \\u0645\\u0646 \\u062F\\u06CC\\u0631\\u0648\\u0632 \\u0628\\u0647 \\u062F\\u0633\\u062A\\u0645 \\u0631\\u0633\\u06CC\\u062F\\u0647 \\u0639\\u0627\\u0644\\u06CC\\u0647 \\u0645\\u0631\\u0633\\u06CC \\u0627\\u0632 \\u062F\\u06CC\\u062C\\u06CC \\u06A9\\u0627\\u0644\\u0627\" #@param {type:\"string\"}\n",
        "from IPython.core.display import display, HTML\n",
        "_normalizer = hazm.Normalizer()\n",
        "if not user_text==\"\":\n",
        "  text_for_test = _normalizer.normalize(user_text)\n",
        "  text_for_test_words = hazm.word_tokenize(text_for_test)\n",
        "  x_text_for_test_words = np.zeros((1,max_no_tokens,vector_size),dtype=K.floatx())\n",
        "  for word in range(0,len(text_for_test_words)):\n",
        "    if word >= max_no_tokens:\n",
        "      break\n",
        "    if text_for_test_words[word] not in fasttext_model.words:\n",
        "      continue\n",
        "    \n",
        "    x_text_for_test_words[0, word, :] = fasttext_model.get_word_vector(text_for_test_words[word])\n",
        "  # print(x_text_for_test_words.shape)\n",
        "  # print(text_for_test_words)\n",
        "  result = model.predict(x_text_for_test_words)\n",
        "  pos_percent = str(int(result[0][1]*100))+\" % \"\n",
        "  neg_percent = str(int(result[0][0]*100))+\" % \"\n",
        "  display(HTML(\"<div style='text-align: center'><div style='display:inline-block'><img height='64px' width='64px' src='https://image.flaticon.com/icons/svg/260/260205.svg'/><h4>{}</h4></div> | <div style='display:inline-block'><img height='64px' width='64px' src='https://image.flaticon.com/icons/svg/260/260206.svg'/><h4>{}</h4></div></div>\".format(pos_percent,neg_percent)))\n",
        "else:\n",
        "  print(\"Please enter your text\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {},
        "colab_type": "code",
        "id": "_kLhLv1h7UD_"
      },
      "outputs": [],
      "source": [
        "user_text = \"\\u062E\\u06CC\\u0644\\u06CC \\u062C\\u0627\\u0644\\u0628\\u0647 \\u0627\\u06CC\\u0646 \\u0645\\u0648\\u0628\\u0627\\u06CC\\u0644 \\u0627\\u0635\\u0644\\u0627 \\u0647\\u0645\\u0647 \\u0686\\u06CC \\u062A\\u0645\\u0627\\u0645\\u0647 \\u0645\\u0646 \\u06A9\\u0647 \\u067E\\u0633\\u0646\\u062F\\u06CC\\u062F\\u0645 \\u0627\\u06CC\\u0646 \\u0645\\u0648\\u0628\\u0627\\u06CC\\u0644 \\u0632\\u06CC\\u0628\\u0627 \\u0631\\u0648\" #@param {type:\"string\"}\n",
        "from IPython.core.display import display, HTML\n",
        "_normalizer = hazm.Normalizer()\n",
        "if not user_text==\"\":\n",
        "  text_for_test = _normalizer.normalize(user_text)\n",
        "  text_for_test_words = hazm.word_tokenize(text_for_test)\n",
        "  x_text_for_test_words = np.zeros((1,max_no_tokens,vector_size),dtype=K.floatx())\n",
        "  for word in range(0,len(text_for_test_words)):\n",
        "    if word >= max_no_tokens:\n",
        "      break\n",
        "    if text_for_test_words[word] not in fasttext_model.words:\n",
        "      continue\n",
        "    \n",
        "    x_text_for_test_words[0, word, :] = fasttext_model.get_word_vector(text_for_test_words[word])\n",
        "  # print(x_text_for_test_words.shape)\n",
        "  # print(text_for_test_words)\n",
        "  result = model.predict(x_text_for_test_words)\n",
        "  pos_percent = str(int(result[0][1]*100))+\" % \"\n",
        "  neg_percent = str(int(result[0][0]*100))+\" % \"\n",
        "  display(HTML(\"<div style='text-align: center'><div style='display:inline-block'><img height='64px' width='64px' src='https://image.flaticon.com/icons/svg/260/260205.svg'/><h4>{}</h4></div> | <div style='display:inline-block'><img height='64px' width='64px' src='https://image.flaticon.com/icons/svg/260/260206.svg'/><h4>{}</h4></div></div>\".format(pos_percent,neg_percent)))\n",
        "else:\n",
        "  print(\"Please enter your text\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "Tutorial.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
