{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ithabibi/Persian-Opinion-Mining-and-Sentiment-Analysis/blob/main/use-model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sMNPBU2OwSBw"
      },
      "source": [
        "# Persian Sentiment Analysis With Fasttext language Model and LSTM neural network\n",
        "### Persian sentiment analysis step by step guide\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "so there are 3 steps we going through with each other "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Step1 Load fasttext model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.fa.300.bin.gz\n",
        "!gunzip /content/cc.fa.300.bin.gz\n",
        "\n",
        "!pip install pybind11==2.11.1\n",
        "!pip install fasttext==0.9.2 \n",
        "\n",
        "!pip install pandas==1.5.3\n",
        "!pip install numpy==1.23\n",
        "!pip install hazm==0.7.0\n",
        "\n",
        "import pandas\n",
        "import random\n",
        "import numpy as np\n",
        "import hazm\n",
        "import keras.backend as K\n",
        "\n",
        "import fasttext \n",
        "\n",
        "%time\n",
        "fasttext_model = fasttext.load_model(\"/content/cc.fa.300.bin\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2 Load LSTM model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!wget https://raw.githubusercontent.com/ithabibi/Persian-Opinion-Mining-and-Sentiment-Analysis/main/learned-persian-sentiment-fasttext.model.zip\n",
        "!unzip /content/learned-persian-sentiment-fasttext.model.zip\n",
        "embedding_dim = 300 #@param {type:\"integer\"}\n",
        "max_vocab_token = 20 #@param {type:\"integer\"}\n",
        "\n",
        "from keras.models import load_model\n",
        "\n",
        "#del model  # deletes the existing model\n",
        "\n",
        "LSTM_model = load_model('/content/learned-persian-sentiment-fasttext.model')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3 inter persian text and booooom!!!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {},
        "colab_type": "code",
        "id": "_kLhLv1h7UD_"
      },
      "outputs": [],
      "source": [
        "user_text = \"\\u0633\\u0644\\u0627\\u0645\" #@param {type:\"string\"}\n",
        "from IPython.core.display import display, HTML\n",
        "_normalizer = hazm.Normalizer()\n",
        "if not user_text==\"\":\n",
        "  text_for_test = _normalizer.normalize(user_text)\n",
        "  text_for_test_words = hazm.word_tokenize(text_for_test)\n",
        "  x_text_for_test_words = np.zeros((1,max_vocab_token,embedding_dim),dtype=K.floatx())\n",
        "  for word in range(0,len(text_for_test_words)):\n",
        "    if word >= max_vocab_token:\n",
        "      break\n",
        "    if text_for_test_words[word] not in fasttext_model.words:\n",
        "      continue\n",
        "    \n",
        "    x_text_for_test_words[0, word, :] = fasttext_model.get_word_vector(text_for_test_words[word])\n",
        "  # print(x_text_for_test_words.shape)\n",
        "  # print(text_for_test_words)\n",
        "  result = LSTM_model.predict(x_text_for_test_words)\n",
        "  pos_percent = str(int(result[0][1]*100))+\" % üòç\"\n",
        "  neg_percent = str(int(result[0][0]*100))+\" % ü§ï\"\n",
        "  display(HTML(\"<div style='text-align: center'><div style='display:inline-block'><img height='64px' width='64px' src='https://image.flaticon.com/icons/svg/260/260205.svg'/><h4>{}</h4></div> | <div style='display:inline-block'><img height='64px' width='64px' src=''/><h4>{}</h4></div></div>\".format(pos_percent,neg_percent)))\n",
        "else:\n",
        "  print(\"Please enter your text\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title using model\n",
        "\n",
        "user_text = \"\\u062E\\u06CC\\u0644\\u06CC \\u06AF\\u0648\\u0634\\u06CC\\u0647 \\u062E\\u0648\\u0628\\u06CC\\u0647. \\u062A\\u0634\\u062E\\u06CC\\u0635 \\u0686\\u0647\\u0631\\u0647 \\u062F\\u0627\\u0631\\u0647. \\u062F\\u0627\\u062E\\u0644 \\u062C\\u0639\\u0628\\u0647 \\u06A9\\u0627\\u0648\\u0631 \\u06AF\\u0648\\u0634\\u06CC \\u0648 \\u0645\\u062D\\u0627\\u0641\\u0638 \\u0635\\u0641\\u062D\\u0647 \\u062F\\u0627\\u0631\\u0647. \\u0645\\u0646 \\u062F\\u06CC\\u0631\\u0648\\u0632 \\u0628\\u0647 \\u062F\\u0633\\u062A\\u0645 \\u0631\\u0633\\u06CC\\u062F\\u0647 \\u0639\\u0627\\u0644\\u06CC\\u0647 \\u0645\\u0631\\u0633\\u06CC \\u0627\\u0632 \\u062F\\u06CC\\u062C\\u06CC \\u06A9\\u0627\\u0644\\u0627\" #@param {type:\"string\"}\n",
        "from IPython.core.display import display, HTML\n",
        "_normalizer = hazm.Normalizer()\n",
        "if not user_text==\"\":\n",
        "  normal_text = _normalizer.normalize(user_text)\n",
        "  tokenized_text = hazm.word_tokenize(normal_text)\n",
        "  \n",
        "  # create and Prepare three dimension tensor (1,20,300) with zero value : (1,number_of_words, dimension_of_fasttext)\n",
        "  vector_text = np.zeros((1,max_vocab_token,embedding_dim),dtype=K.floatx())\n",
        "\n",
        "\n",
        "  for vocabs in range(0,len(tokenized_text)):\n",
        "    if vocabs >= max_vocab_token:\n",
        "      break # If the comment is more than twenty words, only the first twenty words will be considered\n",
        "    if tokenized_text[vocabs] not in fasttext_model.words:\n",
        "      continue # If vocab does not exist in fasttext, every 300 elements of that word's vector remain zero\n",
        "    \n",
        "    vector_text[0, vocabs, :] = fasttext_model.get_word_vector(tokenized_text[vocabs])\n",
        "\n",
        "  # print(vector_text.shape)\n",
        "  # print(vector_text)\n",
        "  result = LSTM_model.predict(vector_text) # the result has two element: [0][1] and [0][0]\n",
        "  pos_percent = str(int(result[0][1]*100))+\" % üòç\"\n",
        "  neg_percent = str(int(result[0][0]*100))+\" % ü§ï\"\n",
        "  display(HTML(\"<div style='text-align: center'><div style='display:inline-block'><img height='64px' width='64px' src='https://images.rawpixel.com/image_png_1000/cHJpdmF0ZS9sci9pbWFnZXMvd2Vic2l0ZS8yMDIyLTEwL3JtNTg2LWlubG92ZWZhY2UtMDFfMS1sOWQzYzlxMC5wbmc.png'/><h4>{}</h4></div> | <div style='display:inline-block'><img height='64px' width='64px' src='https://images.rawpixel.com/image_png_1000/cHJpdmF0ZS9sci9pbWFnZXMvd2Vic2l0ZS8yMDIyLTEwL3JtNTg2LWNyeWluZ2ZhY2UtMDFfMi1sOWQzYnh0MC5wbmc.png'/><h4>{}</h4></div></div>\".format(pos_percent,neg_percent)))\n",
        "else:\n",
        "  print(\"Please enter your text\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "Tutorial.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
